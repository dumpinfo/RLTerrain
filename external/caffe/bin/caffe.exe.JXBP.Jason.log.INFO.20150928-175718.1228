Log file created at: 2015/09/28 17:57:18
Running on machine: JXBP
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0928 17:57:18.843269  6460 solver.cpp:58] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: CPU
net: "examples/mnist/lenet_train_test.prototxt"
I0928 17:57:18.846273  6460 solver.cpp:100] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I0928 17:57:18.851279  6460 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0928 17:57:18.851279  6460 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0928 17:57:18.853282  6460 net.cpp:50] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_leveldb"
    batch_size: 64
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0928 17:57:18.857287  6460 net.cpp:76] Memory required for data: 0
I0928 17:57:18.858288  6460 layer_factory.hpp:76] Creating layer mnist
I0928 17:57:18.868053  6460 common.cpp:32] System entropy source not available, using fallback algorithm to generate seed instead.
I0928 17:57:18.869570  6460 net.cpp:110] Creating Layer mnist
I0928 17:57:18.870559  6460 net.cpp:433] mnist -> data
I0928 17:57:18.871060  6460 net.cpp:433] mnist -> label
I0928 17:57:18.882588  4468 db_leveldb.cpp:17] Opened leveldb examples/mnist/mnist_train_leveldb
I0928 17:57:18.883591  6460 data_layer.cpp:44] output data size: 64,1,28,28
I0928 17:57:18.884093  6460 base_data_layer.cpp:66] Initializing prefetch
I0928 17:57:18.884593  6460 base_data_layer.cpp:69] Prefetch initialized.
I0928 17:57:18.886096  6460 net.cpp:155] Setting up mnist
I0928 17:57:18.886597  6460 net.cpp:163] Top shape: 64 1 28 28 (50176)
I0928 17:57:18.887099  6460 net.cpp:163] Top shape: 64 (64)
I0928 17:57:18.887099  6460 net.cpp:174] Memory required for data: 200960
I0928 17:57:18.889103  6460 layer_factory.hpp:76] Creating layer conv1
I0928 17:57:18.889605  6460 net.cpp:110] Creating Layer conv1
I0928 17:57:18.890106  6460 net.cpp:477] conv1 <- data
I0928 17:57:18.890607  6460 net.cpp:433] conv1 -> conv1
I0928 17:57:18.891609  6460 net.cpp:155] Setting up conv1
I0928 17:57:18.892110  6460 net.cpp:163] Top shape: 64 20 24 24 (737280)
I0928 17:57:18.892612  6460 net.cpp:174] Memory required for data: 3150080
I0928 17:57:18.893616  6460 layer_factory.hpp:76] Creating layer pool1
I0928 17:57:18.894116  6460 net.cpp:110] Creating Layer pool1
I0928 17:57:18.894618  6460 net.cpp:477] pool1 <- conv1
I0928 17:57:18.895118  6460 net.cpp:433] pool1 -> pool1
I0928 17:57:18.895619  6460 net.cpp:155] Setting up pool1
I0928 17:57:18.896121  6460 net.cpp:163] Top shape: 64 20 12 12 (184320)
I0928 17:57:18.896621  6460 net.cpp:174] Memory required for data: 3887360
I0928 17:57:18.897124  6460 layer_factory.hpp:76] Creating layer conv2
I0928 17:57:18.897624  6460 net.cpp:110] Creating Layer conv2
I0928 17:57:18.898125  6460 net.cpp:477] conv2 <- pool1
I0928 17:57:18.898627  6460 net.cpp:433] conv2 -> conv2
I0928 17:57:18.900632  3704 data_layer.cpp:105] Prefetch batch: 14 ms.
I0928 17:57:18.901134  3704 data_layer.cpp:106]      Read time: 2.004 ms.
I0928 17:57:18.901635  3704 data_layer.cpp:107] Transform time: 7.015 ms.
I0928 17:57:18.903638  6460 net.cpp:155] Setting up conv2
I0928 17:57:18.903638  6460 net.cpp:163] Top shape: 64 50 8 8 (204800)
I0928 17:57:18.904139  6460 net.cpp:174] Memory required for data: 4706560
I0928 17:57:18.905141  6460 layer_factory.hpp:76] Creating layer pool2
I0928 17:57:18.905141  6460 net.cpp:110] Creating Layer pool2
I0928 17:57:18.905643  6460 net.cpp:477] pool2 <- conv2
I0928 17:57:18.906144  6460 net.cpp:433] pool2 -> pool2
I0928 17:57:18.906646  6460 net.cpp:155] Setting up pool2
I0928 17:57:18.907148  6460 net.cpp:163] Top shape: 64 50 4 4 (51200)
I0928 17:57:18.907649  6460 net.cpp:174] Memory required for data: 4911360
I0928 17:57:18.908149  6460 layer_factory.hpp:76] Creating layer ip1
I0928 17:57:18.908650  6460 net.cpp:110] Creating Layer ip1
I0928 17:57:18.909152  6460 net.cpp:477] ip1 <- pool2
I0928 17:57:18.909653  6460 net.cpp:433] ip1 -> ip1
I0928 17:57:18.913161  3704 data_layer.cpp:105] Prefetch batch: 11 ms.
I0928 17:57:18.913664  3704 data_layer.cpp:106]      Read time: 1.503 ms.
I0928 17:57:18.914163  3704 data_layer.cpp:107] Transform time: 6.514 ms.
I0928 17:57:18.919176  3704 data_layer.cpp:105] Prefetch batch: 4 ms.
I0928 17:57:18.919176  3704 data_layer.cpp:106]      Read time: 0 ms.
I0928 17:57:18.919678  3704 data_layer.cpp:107] Transform time: 2.004 ms.
I0928 17:57:18.958269  6460 net.cpp:155] Setting up ip1
I0928 17:57:18.959272  6460 net.cpp:163] Top shape: 64 500 (32000)
I0928 17:57:18.959272  6460 net.cpp:174] Memory required for data: 5039360
I0928 17:57:18.960274  6460 layer_factory.hpp:76] Creating layer relu1
I0928 17:57:18.960780  6460 net.cpp:110] Creating Layer relu1
I0928 17:57:18.961277  6460 net.cpp:477] relu1 <- ip1
I0928 17:57:18.961778  6460 net.cpp:419] relu1 -> ip1 (in-place)
I0928 17:57:18.962282  6460 net.cpp:155] Setting up relu1
I0928 17:57:18.962781  6460 net.cpp:163] Top shape: 64 500 (32000)
I0928 17:57:18.962781  6460 net.cpp:174] Memory required for data: 5167360
I0928 17:57:18.963282  6460 layer_factory.hpp:76] Creating layer ip2
I0928 17:57:18.963783  6460 net.cpp:110] Creating Layer ip2
I0928 17:57:18.964284  6460 net.cpp:477] ip2 <- ip1
I0928 17:57:18.964786  6460 net.cpp:433] ip2 -> ip2
I0928 17:57:18.966289  6460 net.cpp:155] Setting up ip2
I0928 17:57:18.966804  6460 net.cpp:163] Top shape: 64 10 (640)
I0928 17:57:18.967293  6460 net.cpp:174] Memory required for data: 5169920
I0928 17:57:18.967793  6460 layer_factory.hpp:76] Creating layer loss
I0928 17:57:18.968296  6460 net.cpp:110] Creating Layer loss
I0928 17:57:18.968794  6460 net.cpp:477] loss <- ip2
I0928 17:57:18.969296  6460 net.cpp:477] loss <- label
I0928 17:57:18.969799  6460 net.cpp:433] loss -> loss
I0928 17:57:18.970299  6460 layer_factory.hpp:76] Creating layer loss
I0928 17:57:18.971300  6460 net.cpp:155] Setting up loss
I0928 17:57:18.971300  6460 net.cpp:163] Top shape: (1)
I0928 17:57:18.971802  6460 net.cpp:168]     with loss weight 1
I0928 17:57:18.972303  6460 net.cpp:174] Memory required for data: 5169924
I0928 17:57:18.972806  6460 net.cpp:236] loss needs backward computation.
I0928 17:57:18.973305  6460 net.cpp:236] ip2 needs backward computation.
I0928 17:57:18.973809  6460 net.cpp:236] relu1 needs backward computation.
I0928 17:57:18.974810  6460 net.cpp:236] ip1 needs backward computation.
I0928 17:57:18.975311  6460 net.cpp:236] pool2 needs backward computation.
I0928 17:57:18.975812  6460 net.cpp:236] conv2 needs backward computation.
I0928 17:57:18.976814  6460 net.cpp:236] pool1 needs backward computation.
I0928 17:57:18.977818  6460 net.cpp:236] conv1 needs backward computation.
I0928 17:57:18.978819  6460 net.cpp:240] mnist does not need backward computation.
I0928 17:57:18.979321  6460 net.cpp:283] This network produces output loss
I0928 17:57:18.980324  6460 net.cpp:297] Network initialization done.
I0928 17:57:18.980324  6460 net.cpp:298] Memory required for data: 5169924
I0928 17:57:18.986336  6460 solver.cpp:190] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I0928 17:57:18.987339  6460 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0928 17:57:18.989346  6460 net.cpp:50] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_leveldb"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0928 17:57:18.995360  6460 net.cpp:76] Memory required for data: 0
I0928 17:57:18.998869  6460 layer_factory.hpp:76] Creating layer mnist
I0928 17:57:19.000872  6460 net.cpp:110] Creating Layer mnist
I0928 17:57:19.001374  6460 net.cpp:433] mnist -> data
I0928 17:57:19.001874  6460 net.cpp:433] mnist -> label
I0928 17:57:19.012900  8252 db_leveldb.cpp:17] Opened leveldb examples/mnist/mnist_test_leveldb
I0928 17:57:19.013903  6460 data_layer.cpp:44] output data size: 100,1,28,28
I0928 17:57:19.014906  6460 base_data_layer.cpp:66] Initializing prefetch
I0928 17:57:19.015408  6460 base_data_layer.cpp:69] Prefetch initialized.
I0928 17:57:19.016911  6460 net.cpp:155] Setting up mnist
I0928 17:57:19.017913  6460 net.cpp:163] Top shape: 100 1 28 28 (78400)
I0928 17:57:19.018415  6460 net.cpp:163] Top shape: 100 (100)
I0928 17:57:19.018918  6460 net.cpp:174] Memory required for data: 314000
I0928 17:57:19.019417  6460 layer_factory.hpp:76] Creating layer label_mnist_1_split
I0928 17:57:19.019917  6460 net.cpp:110] Creating Layer label_mnist_1_split
I0928 17:57:19.020419  6460 net.cpp:477] label_mnist_1_split <- label
I0928 17:57:19.021421  6460 net.cpp:433] label_mnist_1_split -> label_mnist_1_split_0
I0928 17:57:19.022423  6460 net.cpp:433] label_mnist_1_split -> label_mnist_1_split_1
I0928 17:57:19.022925  6460 net.cpp:155] Setting up label_mnist_1_split
I0928 17:57:19.023427  6460 net.cpp:163] Top shape: 100 (100)
I0928 17:57:19.023427  6460 net.cpp:163] Top shape: 100 (100)
I0928 17:57:19.023427 15740 data_layer.cpp:105] Prefetch batch: 7 ms.
I0928 17:57:19.023927  6460 net.cpp:174] Memory required for data: 314800
I0928 17:57:19.023927 15740 data_layer.cpp:106]      Read time: 1.504 ms.
I0928 17:57:19.024428  6460 layer_factory.hpp:76] Creating layer conv1
I0928 17:57:19.024428 15740 data_layer.cpp:107] Transform time: 4.511 ms.
I0928 17:57:19.024930  6460 net.cpp:110] Creating Layer conv1
I0928 17:57:19.025432  6460 net.cpp:477] conv1 <- data
I0928 17:57:19.025933  6460 net.cpp:433] conv1 -> conv1
I0928 17:57:19.026433  6460 net.cpp:155] Setting up conv1
I0928 17:57:19.027436  6460 net.cpp:163] Top shape: 100 20 24 24 (1152000)
I0928 17:57:19.027937  6460 net.cpp:174] Memory required for data: 4922800
I0928 17:57:19.028439  6460 layer_factory.hpp:76] Creating layer pool1
I0928 17:57:19.028939  6460 net.cpp:110] Creating Layer pool1
I0928 17:57:19.028939  6460 net.cpp:477] pool1 <- conv1
I0928 17:57:19.029942  6460 net.cpp:433] pool1 -> pool1
I0928 17:57:19.029942  6460 net.cpp:155] Setting up pool1
I0928 17:57:19.030443  6460 net.cpp:163] Top shape: 100 20 12 12 (288000)
I0928 17:57:19.030944  6460 net.cpp:174] Memory required for data: 6074800
I0928 17:57:19.031445  6460 layer_factory.hpp:76] Creating layer conv2
I0928 17:57:19.031947  6460 net.cpp:110] Creating Layer conv2
I0928 17:57:19.031947  6460 net.cpp:477] conv2 <- pool1
I0928 17:57:19.032449  6460 net.cpp:433] conv2 -> conv2
I0928 17:57:19.033953 15740 data_layer.cpp:105] Prefetch batch: 9 ms.
I0928 17:57:19.034453 15740 data_layer.cpp:106]      Read time: 1.001 ms.
I0928 17:57:19.034453 15740 data_layer.cpp:107] Transform time: 4.013 ms.
I0928 17:57:19.037962  6460 net.cpp:155] Setting up conv2
I0928 17:57:19.037962  6460 net.cpp:163] Top shape: 100 50 8 8 (320000)
I0928 17:57:19.038462  6460 net.cpp:174] Memory required for data: 7354800
I0928 17:57:19.038964  6460 layer_factory.hpp:76] Creating layer pool2
I0928 17:57:19.039464  6460 net.cpp:110] Creating Layer pool2
I0928 17:57:19.039965  6460 net.cpp:477] pool2 <- conv2
I0928 17:57:19.040467  6460 net.cpp:433] pool2 -> pool2
I0928 17:57:19.040467  6460 net.cpp:155] Setting up pool2
I0928 17:57:19.040968  6460 net.cpp:163] Top shape: 100 50 4 4 (80000)
I0928 17:57:19.041470  6460 net.cpp:174] Memory required for data: 7674800
I0928 17:57:19.041970  6460 layer_factory.hpp:76] Creating layer ip1
I0928 17:57:19.041970  6460 net.cpp:110] Creating Layer ip1
I0928 17:57:19.042472  6460 net.cpp:477] ip1 <- pool2
I0928 17:57:19.042973  6460 net.cpp:433] ip1 -> ip1
I0928 17:57:19.044981 15740 data_layer.cpp:105] Prefetch batch: 10 ms.
I0928 17:57:19.044981 15740 data_layer.cpp:106]      Read time: 1.006 ms.
I0928 17:57:19.045480 15740 data_layer.cpp:107] Transform time: 4.51 ms.
I0928 17:57:19.088582  6460 net.cpp:155] Setting up ip1
I0928 17:57:19.089093  6460 net.cpp:163] Top shape: 100 500 (50000)
I0928 17:57:19.089586  6460 net.cpp:174] Memory required for data: 7874800
I0928 17:57:19.090086  6460 layer_factory.hpp:76] Creating layer relu1
I0928 17:57:19.090086  6460 net.cpp:110] Creating Layer relu1
I0928 17:57:19.090587  6460 net.cpp:477] relu1 <- ip1
I0928 17:57:19.091089  6460 net.cpp:419] relu1 -> ip1 (in-place)
I0928 17:57:19.091089  6460 net.cpp:155] Setting up relu1
I0928 17:57:19.091589  6460 net.cpp:163] Top shape: 100 500 (50000)
I0928 17:57:19.091589  6460 net.cpp:174] Memory required for data: 8074800
I0928 17:57:19.092100  6460 layer_factory.hpp:76] Creating layer ip2
I0928 17:57:19.092592  6460 net.cpp:110] Creating Layer ip2
I0928 17:57:19.092592  6460 net.cpp:477] ip2 <- ip1
I0928 17:57:19.093093  6460 net.cpp:433] ip2 -> ip2
I0928 17:57:19.094597  6460 net.cpp:155] Setting up ip2
I0928 17:57:19.094597  6460 net.cpp:163] Top shape: 100 10 (1000)
I0928 17:57:19.095098  6460 net.cpp:174] Memory required for data: 8078800
I0928 17:57:19.095599  6460 layer_factory.hpp:76] Creating layer ip2_ip2_0_split
I0928 17:57:19.096101  6460 net.cpp:110] Creating Layer ip2_ip2_0_split
I0928 17:57:19.096101  6460 net.cpp:477] ip2_ip2_0_split <- ip2
I0928 17:57:19.096602  6460 net.cpp:433] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0928 17:57:19.097103  6460 net.cpp:433] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0928 17:57:19.097604  6460 net.cpp:155] Setting up ip2_ip2_0_split
I0928 17:57:19.097604  6460 net.cpp:163] Top shape: 100 10 (1000)
I0928 17:57:19.098105  6460 net.cpp:163] Top shape: 100 10 (1000)
I0928 17:57:19.098608  6460 net.cpp:174] Memory required for data: 8086800
I0928 17:57:19.098608  6460 layer_factory.hpp:76] Creating layer accuracy
I0928 17:57:19.099107  6460 net.cpp:110] Creating Layer accuracy
I0928 17:57:19.099609  6460 net.cpp:477] accuracy <- ip2_ip2_0_split_0
I0928 17:57:19.099609  6460 net.cpp:477] accuracy <- label_mnist_1_split_0
I0928 17:57:19.100111  6460 net.cpp:433] accuracy -> accuracy
I0928 17:57:19.100111  6460 net.cpp:155] Setting up accuracy
I0928 17:57:19.100611  6460 net.cpp:163] Top shape: (1)
I0928 17:57:19.100611  6460 net.cpp:174] Memory required for data: 8086804
I0928 17:57:19.101114  6460 layer_factory.hpp:76] Creating layer loss
I0928 17:57:19.101614  6460 net.cpp:110] Creating Layer loss
I0928 17:57:19.101614  6460 net.cpp:477] loss <- ip2_ip2_0_split_1
I0928 17:57:19.102124  6460 net.cpp:477] loss <- label_mnist_1_split_1
I0928 17:57:19.102617  6460 net.cpp:433] loss -> loss
I0928 17:57:19.103117  6460 layer_factory.hpp:76] Creating layer loss
I0928 17:57:19.103117  6460 net.cpp:155] Setting up loss
I0928 17:57:19.103621  6460 net.cpp:163] Top shape: (1)
I0928 17:57:19.104120  6460 net.cpp:168]     with loss weight 1
I0928 17:57:19.104120  6460 net.cpp:174] Memory required for data: 8086808
I0928 17:57:19.104621  6460 net.cpp:236] loss needs backward computation.
I0928 17:57:19.105123  6460 net.cpp:240] accuracy does not need backward computation.
I0928 17:57:19.105123  6460 net.cpp:236] ip2_ip2_0_split needs backward computation.
I0928 17:57:19.105625  6460 net.cpp:236] ip2 needs backward computation.
I0928 17:57:19.106124  6460 net.cpp:236] relu1 needs backward computation.
I0928 17:57:19.106124  6460 net.cpp:236] ip1 needs backward computation.
I0928 17:57:19.106626  6460 net.cpp:236] pool2 needs backward computation.
I0928 17:57:19.107127  6460 net.cpp:236] conv2 needs backward computation.
I0928 17:57:19.107127  6460 net.cpp:236] pool1 needs backward computation.
I0928 17:57:19.107628  6460 net.cpp:236] conv1 needs backward computation.
I0928 17:57:19.108130  6460 net.cpp:240] label_mnist_1_split does not need backward computation.
I0928 17:57:19.108631  6460 net.cpp:240] mnist does not need backward computation.
I0928 17:57:19.108631  6460 net.cpp:283] This network produces output accuracy
I0928 17:57:19.109133  6460 net.cpp:283] This network produces output loss
I0928 17:57:19.109633  6460 net.cpp:297] Network initialization done.
I0928 17:57:19.110136  6460 net.cpp:298] Memory required for data: 8086808
I0928 17:57:19.111137  6460 solver.cpp:69] Solver scaffolding done.
I0928 17:57:19.113142  6460 caffe.cpp:211] Starting Optimization
I0928 17:57:19.113644  6460 solver.cpp:297] Solving LeNet
I0928 17:57:19.114145  6460 solver.cpp:298] Learning Rate Policy: inv
I0928 17:57:19.115146  6460 solver.cpp:350] Iteration 0, Testing net (#0)
I0928 17:57:19.115648  6460 net.cpp:781] Copying source layer mnist
I0928 17:57:19.116149  6460 net.cpp:781] Copying source layer conv1
I0928 17:57:19.116149  6460 net.cpp:781] Copying source layer pool1
I0928 17:57:19.116650  6460 net.cpp:781] Copying source layer conv2
I0928 17:57:19.116650  6460 net.cpp:781] Copying source layer pool2
I0928 17:57:19.117151  6460 net.cpp:781] Copying source layer ip1
I0928 17:57:19.117652  6460 net.cpp:781] Copying source layer relu1
I0928 17:57:19.118154  6460 net.cpp:781] Copying source layer ip2
I0928 17:57:19.118154  6460 net.cpp:781] Copying source layer loss
I0928 17:57:19.119156  6460 base_